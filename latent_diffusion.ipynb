{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88862ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import guided_diffusion.guided_diffusion_1d\n",
    "from peptidevae.load_vae import load_vae, vae_decode\n",
    "import classifier.load_classifier as lc\n",
    "\n",
    "import peptide_dataset\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import peptidevae.load_vae\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "importlib.reload(peptide_dataset)\n",
    "importlib.reload(peptidevae.load_vae)\n",
    "importlib.reload(lc)\n",
    "importlib.reload(guided_diffusion.guided_diffusion_1d)\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e76535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\peptidevae\\load_vae.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path_to_vae_statedict, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Get VAE for viewing output: should take ~30 seconds, kinda slow\n",
    "vae, dataobj = load_vae(\"peptidevae/checkpoints/dim128_k1_kl0001_eff256_dff256_pious-sea-2_model_state_epoch_118.pkl\", dim=256, max_string_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38600f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "train_batch_size = 16\n",
    "sample_batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffed58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full dataset of 10274723 examples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_module = peptide_dataset.LatentDataModule(batch_size=train_batch_size, train_val_split=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77443291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_latent(latent_batch):\n",
    "    with torch.no_grad():\n",
    "        return None\n",
    "        # return vae_decode(latent_batch, vae, dataobj, device=device)\n",
    "\n",
    "def sample_diffusion(diffusion_model):\n",
    "    diffusion_model.eval()\n",
    "    with torch.no_grad():\n",
    "        latents = diffusion_model.sample(batch_size=sample_batch_size)\n",
    "        latents = latents.reshape(sample_batch_size, latent_dim)\n",
    "        return latents, decode_latent(latents)\n",
    "    \n",
    "def sample_with_guidance(diffusion_model, classifier, guidance_scale=4.0, target_class=1, batch_size=sample_batch_size):\n",
    "    def cond_fn(x, t):\n",
    "        x_in = x.reshape(sample_batch_size, latent_dim)\n",
    "\n",
    "        x_in = x_in.detach().requires_grad_(True)\n",
    "\n",
    "        with torch.enable_grad():\n",
    "\n",
    "            # logits:\n",
    "            _, logits, _ = lc.predict(classifier, x_in, device)\n",
    "\n",
    "            # loss = -logits[:, target_class].sum()\n",
    "\n",
    "            sign = 1 if target_class == 0 else -1\n",
    "            loss = sign * logits.sum()\n",
    "            \n",
    "            grad = torch.autograd.grad(loss, x_in)[0]\n",
    "\n",
    "        # negative guidance scale, because we minimize lossOk,\n",
    "            grad = grad.reshape(sample_batch_size, 1, latent_dim)\n",
    "            return -guidance_scale * grad\n",
    "    \n",
    "    diffusion_model.eval()\n",
    "    with torch.no_grad():\n",
    "        latents = diffusion_model.sample(batch_size=sample_batch_size, cond_fn=cond_fn, guidance_kwargs={})\n",
    "        latents = latents.reshape(sample_batch_size, latent_dim)\n",
    "        return latents, decode_latent(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f523584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creates dataloader and checks that it works\n",
    "importlib.reload(peptide_dataset)\n",
    "\n",
    "data_loader = data_module.full_dataloader\n",
    "for batch in data_loader:\n",
    "    latent = batch['latent']\n",
    "    print(decode_latent(latent))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2535ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\classifier\\load_classifier.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Create the classifier (pre-trained)\n",
    "classf, _ = lc.load_model(\"classifier/best_model.pt\")\n",
    "\n",
    "# Simple test to check classifier is working\n",
    "test_latents = np.load('classifier/test_peptides_latents.npy') \n",
    "labels = pd.read_csv('classifier/test_peptides.csv')['labels'].to_list()\n",
    "test_latents = torch.Tensor(test_latents).to(device)\n",
    "\n",
    "predictions, logits, probabilities = lc.predict(classf, test_latents, device)\n",
    "accuracy = np.mean(predictions.to('cpu').numpy() == labels)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# predictions, _, _ = lc.predict(classf, test_latents, device)\n",
    "# print(f\"Prediction: {predictions.sum() / len(predictions)}\")\n",
    "\n",
    "def predict_exctinct(latents, classf):\n",
    "    predictions, _, probabilities = lc.predict(classf, latents, device)\n",
    "    for i in range(len(predictions)):\n",
    "        print(f\"Predicted class {predictions[i]} with probability of predictions=0 at {probabilities[i][0] * 100.0}%\")\n",
    "    return predictions, probabilities\n",
    "\n",
    "def get_extinct_prediction_percent(diffusion, classf, guidance_scale, num_samples=64):\n",
    "    classf = classf.to(device)\n",
    "    classf.eval()\n",
    "    diffusion.eval()\n",
    "\n",
    "    latents, _ = sample_with_guidance(diffusion_model=diffusion, classifier=classf, guidance_scale=guidance_scale, batch_size=64)\n",
    "    predictions, _, _ = lc.predict(classf, latents, device)\n",
    "    \n",
    "    print(f\"Prediction: {predictions.sum() / len(predictions)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2524511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion(diffusion_model, classifier, dataloader=data_loader, batch_size=train_batch_size, epochs=10, lr=1e-4, device=device):\n",
    "    model = diffusion_model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch}\")\n",
    "\n",
    "        for batch_idx, batch in progress_bar:\n",
    "            latent = batch['latent']\n",
    "            latent = latent.to(device)\n",
    "\n",
    "            # IMPORTANT: the dataloader stores objects of shape (b, n), but the\n",
    "            # UNET / diffusion want (b, 1, n)\n",
    "            latent = latent.reshape(batch_size, 1, latent_dim)\n",
    "\n",
    "            # When we sample, we will unshape this\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(latent)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Batch: {batch_idx}: Batch Loss: {loss.item()}\")\n",
    "\n",
    "            if batch_idx % 10000 == 0:\n",
    "                print(f\"Validation: \")\n",
    "                get_extinct_prediction_percent(diffusion_model, classifier, guidance_scale=5.0)\n",
    "                model.train()\n",
    "        \n",
    "        torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, 'diff_checkpoints/best_model.pt')\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch}, Average Loss: {epoch_loss / len(dataloader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca900b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e9b757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Train the diffusion model\n",
    "importlib.reload(guided_diffusion.guided_diffusion_1d)\n",
    "importlib.reload(lc)\n",
    "importlib.reload(peptidevae.load_vae)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "epochs = 1\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "unet_dim = latent_dim # for now, matches latent dim, may change\n",
    "unet_model = guided_diffusion.guided_diffusion_1d.Unet1D(\n",
    "    dim = unet_dim,\n",
    "    channels=1,\n",
    "    dim_mults=(1, 2, 4)\n",
    ").to(device)\n",
    "\n",
    "diffusion_model = guided_diffusion.guided_diffusion_1d.GaussianDiffusion1D(\n",
    "    unet_model,\n",
    "    seq_length=latent_dim,\n",
    "    timesteps=100,\n",
    "    objective='pred_v'\n",
    ").to(device)\n",
    "\n",
    "classifier = classf.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "133376b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/642171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 0: Batch Loss: 0.36441606283187866\n",
      "Validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 100/100 [00:01<00:00, 70.33it/s]\n",
      "Epoch 0:   0%|          | 3/642171 [00:01<92:17:45,  1.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 101/642171 [00:10<15:27:05, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 100: Batch Loss: 0.11089465022087097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 203/642171 [00:19<15:25:49, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 200: Batch Loss: 0.10196179151535034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 303/642171 [00:27<15:23:47, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 300: Batch Loss: 0.3407649099826813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 403/642171 [00:36<15:27:21, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 400: Batch Loss: 0.2599904537200928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 503/642171 [00:45<15:31:46, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 500: Batch Loss: 0.24295203387737274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 603/642171 [00:53<15:26:04, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 600: Batch Loss: 0.18528227508068085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 703/642171 [01:02<15:16:40, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 700: Batch Loss: 0.2032776176929474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 803/642171 [01:11<15:23:17, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 800: Batch Loss: 0.14893460273742676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 903/642171 [01:19<15:23:38, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 900: Batch Loss: 0.23710328340530396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 999/642171 [01:28<15:43:37, 11.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain_diffusion\u001b[39m\u001b[34m(diffusion_model, classifier, dataloader, batch_size, epochs, lr, device)\u001b[39m\n\u001b[32m     20\u001b[39m optimizer.zero_grad()\n\u001b[32m     21\u001b[39m loss = model(latent)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m optimizer.step()\n\u001b[32m     25\u001b[39m epoch_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\.venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_diffusion(diffusion_model, classifier, dataloader=data_loader, batch_size=train_batch_size, epochs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
