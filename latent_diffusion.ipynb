{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88862ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import guided_diffusion.guided_diffusion_1d\n",
    "from peptidevae.load_vae import load_vae, vae_decode\n",
    "import classifier.load_classifier as lc\n",
    "\n",
    "import peptide_dataset\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import peptidevae.load_vae\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "importlib.reload(peptide_dataset)\n",
    "importlib.reload(peptidevae.load_vae)\n",
    "importlib.reload(lc)\n",
    "importlib.reload(guided_diffusion.guided_diffusion_1d)\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e76535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\peptidevae\\load_vae.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path_to_vae_statedict, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Get VAE for viewing output: should take ~30 seconds, kinda slow\n",
    "vae, dataobj = load_vae(\"peptidevae/checkpoints/dim128_k1_kl0001_eff256_dff256_pious-sea-2_model_state_epoch_118.pkl\", dim=256, max_string_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38600f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "train_batch_size = 16\n",
    "sample_batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffed58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full dataset of 10274723 examples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_module = peptide_dataset.LatentDataModule(batch_size=train_batch_size, train_val_split=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77443291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_latent(latent_batch):\n",
    "    with torch.no_grad():\n",
    "        return None\n",
    "        # return vae_decode(latent_batch, vae, dataobj, device=device)\n",
    "\n",
    "def sample_diffusion(diffusion_model):\n",
    "    diffusion_model.eval()\n",
    "    with torch.no_grad():\n",
    "        latents = diffusion_model.sample(batch_size=sample_batch_size)\n",
    "        latents = latents.reshape(sample_batch_size, latent_dim)\n",
    "        return latents, decode_latent(latents)\n",
    "    \n",
    "def sample_with_guidance(diffusion_model, classifier, guidance_scale=4.0, target_class=1, batch_size=sample_batch_size):\n",
    "    def cond_fn(x, t):\n",
    "        x_in = x.reshape(sample_batch_size, latent_dim)\n",
    "\n",
    "        x_in = x_in.detach().requires_grad_(True)\n",
    "\n",
    "        with torch.enable_grad():\n",
    "\n",
    "            # logits:\n",
    "            _, logits, _ = lc.predict(classifier, x_in, device)\n",
    "\n",
    "            # loss = -logits[:, target_class].sum()\n",
    "\n",
    "            sign = 1 if target_class == 0 else -1\n",
    "            loss = sign * logits.sum()\n",
    "            \n",
    "            grad = torch.autograd.grad(loss, x_in)[0]\n",
    "\n",
    "        # negative guidance scale, because we minimize lossOk,\n",
    "            grad = grad.reshape(sample_batch_size, 1, latent_dim)\n",
    "            return -guidance_scale * grad\n",
    "    \n",
    "    diffusion_model.eval()\n",
    "    with torch.no_grad():\n",
    "        latents = diffusion_model.sample(batch_size=sample_batch_size, cond_fn=cond_fn, guidance_kwargs={})\n",
    "        latents = latents.reshape(sample_batch_size, latent_dim)\n",
    "        return latents, decode_latent(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f523584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "['FLPQGTPSPLIPMLLILETISLFIQPMALAVRLTANITAGHLLIHL', 'VMATAFMGYVLPWGQMSFWGATVITNLLSAIPYIGPTLVEWIW', 'QDIRKMGGMMYTLPFTSSCLMIGTLALTGMPFMTGFYSKDHII', 'AFMGYVLPWGQMSFWGATVITNLLSAIPYIGTTLVEW', 'MLTMIPILMKTTNPRSTEAATKYFMTQATASMMLMMALTINLVYS', 'LLVLFIMFQLKVSNHMYPMNPELIKPKLKEQKTPWE', 'QCPKPTLQQISHIAQQLGLEKDVVRVWFCNRRQKGKRSSSDYSQREDF', 'LASATNTWEIQQL', 'IQQAFSHTQAPTLPLLGLILAATGKSAQ', 'MAIAMLSLLSLFFYLRLAYHSTIILPPNSSNH', 'DVIRESTFQGHHTTTVQKGLRYGMVLFIVSEVFFFLGFFW', 'MISHIVTYYSGKKEPFGYMGMVWAMVSIGFLGFIVWA', 'PILIAMAFLMLTERKILGYMQLRKGPNVVGPYGL', 'IPMITNSLT', 'PWASQTSKLPTMLITALL', 'PPLSGFLPKWMIIQEMTKNSLIIMPTMMAI']\n"
     ]
    }
   ],
   "source": [
    "# Creates dataloader and checks that it works\n",
    "importlib.reload(peptide_dataset)\n",
    "\n",
    "data_loader = data_module.full_dataloader\n",
    "for batch in data_loader:\n",
    "    latent = batch['latent']\n",
    "    print(decode_latent(latent))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2535ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier (pre-trained)\n",
    "classf, _ = lc.load_model(\"classifier/best_model.pt\")\n",
    "\n",
    "# Simple test to check classifier is working\n",
    "test_latents = np.load('classifier/test_peptides_latents.npy') \n",
    "labels = pd.read_csv('classifier/test_peptides.csv')['labels'].to_list()\n",
    "test_latents = torch.Tensor(test_latents).to(device)\n",
    "\n",
    "predictions, logits, probabilities = lc.predict(classf, test_latents, device)\n",
    "accuracy = np.mean(predictions.to('cpu').numpy() == labels)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# predictions, _, _ = lc.predict(classf, test_latents, device)\n",
    "# print(f\"Prediction: {predictions.sum() / len(predictions)}\")\n",
    "\n",
    "def predict_exctinct(latents, classf):\n",
    "    predictions, _, probabilities = lc.predict(classf, latents, device)\n",
    "    for i in range(len(predictions)):\n",
    "        print(f\"Predicted class {predictions[i]} with probability of predictions=0 at {probabilities[i][0] * 100.0}%\")\n",
    "    return predictions, probabilities\n",
    "\n",
    "def get_extinct_prediction_percent(diffusion, guidance_scale, num_samples=64):\n",
    "    classf = classf.to(device)\n",
    "    classf.eval()\n",
    "    diffusion.eval()\n",
    "\n",
    "    latents, _ = sample_with_guidance(diffusion_model=diffusion, classifier=classf, guidance_scale=guidance_scale, batch_size=64)\n",
    "    predictions, _, _ = lc.predict(classf, latents, device)\n",
    "    \n",
    "    print(f\"Prediction: {predictions.sum() / len(predictions)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion(diffusion_model, dataloader=data_loader, batch_size=train_batch_size, epochs=10, lr=1e-4, device=device):\n",
    "    model = diffusion_model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch}\")\n",
    "\n",
    "        for batch_idx, batch in progress_bar:\n",
    "            latent = batch['latent']\n",
    "            latent = latent.to(device)\n",
    "\n",
    "            # IMPORTANT: the dataloader stores objects of shape (b, n), but the\n",
    "            # UNET / diffusion want (b, 1, n)\n",
    "            latent = latent.reshape(batch_size, 1, latent_dim)\n",
    "\n",
    "            # When we sample, we will unshape this\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(latent)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Batch: {batch_idx}: Batch Loss: {loss.item()}\")\n",
    "\n",
    "            if batch_idx % 10000 == 0:\n",
    "                get_extinct_prediction_percent(diffusion_model, guidance_scale=5.0)\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch}, Average Loss: {epoch_loss / len(dataloader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2e628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\2023r\\Documents\\GuidedDiffusionProject\\classifier\\load_classifier.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9b757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [00:13<00:00, 73.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the diffusion model\n",
    "importlib.reload(guided_diffusion.guided_diffusion_1d)\n",
    "importlib.reload(lc)\n",
    "importlib.reload(peptidevae.load_vae)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "epochs = 1\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "unet_dim = latent_dim # for now, matches latent dim, may change\n",
    "unet_model = guided_diffusion.guided_diffusion_1d.Unet1D(\n",
    "    dim = unet_dim,\n",
    "    channels=1,\n",
    "    dim_mults=(1, 2, 4, 8)\n",
    ").to(device)\n",
    "\n",
    "diffusion_model = guided_diffusion.guided_diffusion_1d.GaussianDiffusion1D(\n",
    "    unet_model,\n",
    "    seq_length=latent_dim,\n",
    "    timesteps=1000,\n",
    "    objective='pred_v'\n",
    ").to(device)\n",
    "\n",
    "classifier = classf.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3deba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.7466, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "        1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
       "        0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
       "        1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
       "        0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
       "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "        0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
       "        1.0000, 0.0033, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
       "        1.0000, 0.4705, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
       "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "        1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
       "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
       "        1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
       "        0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
       "        1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
       "        0.3164, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "        1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
       "        0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
       "        0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
       "        0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "133376b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/642171 [00:00<107:29:56,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch: 0: Batch Loss: 0.8120216131210327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 72/642171 [00:06<16:37:05, 10.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtrain_diffusion\u001b[39m\u001b[34m(diffusion_model, dataloader, batch_size, epochs, lr, device)\u001b[39m\n\u001b[32m     22\u001b[39m loss.backward()\n\u001b[32m     23\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m epoch_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_idx % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Batch Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_diffusion(diffusion_model, dataloader=data_loader, batch_size=train_batch_size, epochs=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
